"""
PM Agent Worker Lambda Function

This Lambda function processes planning tasks from SQS queue.
It integrates the existing PM agent logic for project planning and task breakdown.

Requirements: 1.3, 2.2
"""

import json
import os
import logging
from datetime import datetime
from typing import Dict, Any, List
import boto3
from botocore.exceptions import ClientError

# Import structured logger
import sys
sys.path.insert(0, '/opt/python')
from utils.logger import get_logger, log_lambda_event, log_lambda_response, log_error

# Initialize structured logger
logger = get_logger('pm-agent')

# Initialize AWS clients
dynamodb = boto3.resource('dynamodb')
s3_client = boto3.client('s3')
sqs_client = boto3.client('sqs')
ssm_client = boto3.client('ssm')

# Environment variables
DYNAMODB_TABLE_NAME = os.environ.get('DYNAMODB_TABLE_NAME', 'agenticai-data')
S3_BUCKET_NAME = os.environ.get('S3_BUCKET_NAME', 'agenticai-generated-code')
SQS_QUEUE_URL_DEV = os.environ.get('SQS_QUEUE_URL_DEV', '')
GEMINI_API_KEY = None  # Will be loaded from Parameter Store

# DynamoDB table
table = dynamodb.Table(DYNAMODB_TABLE_NAME)


def get_secret(name: str) -> str:
    """Retrieve secret from Parameter Store."""
    try:
        response = ssm_client.get_parameter(
            Name=f'/agenticai/{name}',
            WithDecryption=True
        )
        return response['Parameter']['Value']
    except ClientError as e:
        logger.error(
            f"Error retrieving secret {name}",
            event_type='parameter_store_error',
            error=e,
            parameter_name=name
        )
        raise


def initialize_api_key():
    """Initialize API key from Parameter Store (lazy loading)."""
    global GEMINI_API_KEY
    if GEMINI_API_KEY is None:
        GEMINI_API_KEY = get_secret('gemini-api-key')
        os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY


def call_gemini_api(prompt: str, system_prompt: str) -> str:
    """
    Call Gemini API for plan generation.
    
    This is a simplified version. In production, you would import
    the actual LLM setup utilities.
    """
    import google.generativeai as genai
    
    initialize_api_key()
    genai.configure(api_key=GEMINI_API_KEY)
    
    model = genai.GenerativeModel(
        model_name='gemini-2.0-flash-exp',
        system_instruction=system_prompt
    )
    
    response = model.generate_content(prompt)
    return response.text


def parse_plan_from_response(response_text: str) -> Dict[str, Any]:
    """
    Parse plan from LLM response.
    
    Extracts structured plan data from the LLM's text response.
    """
    # Simple parsing logic - in production, use the actual PlanParser
    plan = {
        'title': 'Generated Plan',
        'description': 'Plan generated by PM Agent',
        'tasks': [],
        'raw_response': response_text
    }
    
    # Extract tasks from response (simplified)
    lines = response_text.split('\n')
    current_task = None
    
    for line in lines:
        line = line.strip()
        if line.startswith('Task ') or line.startswith('- '):
            if current_task:
                plan['tasks'].append(current_task)
            current_task = {
                'title': line.lstrip('Task -').strip(),
                'description': '',
                'status': 'pending'
            }
        elif current_task and line:
            current_task['description'] += line + ' '
    
    if current_task:
        plan['tasks'].append(current_task)
    
    return plan


def save_plan_to_dynamodb(project_id: str, plan: Dict[str, Any]) -> str:
    """Save generated plan to DynamoDB."""
    plan_id = f"plan_{datetime.utcnow().strftime('%Y%m%d_%H%M%S')}"
    
    plan_item = {
        'PK': f'PROJECT#{project_id}',
        'SK': f'PLAN#{plan_id}',
        'EntityType': 'Plan',
        'id': plan_id,
        'project_id': project_id,
        'title': plan.get('title', 'Generated Plan'),
        'description': plan.get('description', ''),
        'tasks': plan.get('tasks', []),
        'created_at': datetime.utcnow().isoformat(),
        'status': 'generated'
    }
    
    table.put_item(Item=plan_item)
    logger.info(
        f"Saved plan {plan_id} for project {project_id}",
        event_type='plan_saved',
        project_id=project_id,
        plan_id=plan_id,
        tasks_count=len(plan.get('tasks', []))
    )
    
    return plan_id


def save_plan_to_s3(project_id: str, plan_id: str, plan: Dict[str, Any]):
    """Save plan details to S3 for long-term storage."""
    try:
        s3_key = f'plans/{project_id}/{plan_id}.json'
        s3_client.put_object(
            Bucket=S3_BUCKET_NAME,
            Key=s3_key,
            Body=json.dumps(plan, indent=2),
            ContentType='application/json'
        )
        logger.info(
            f"Saved plan to S3: {s3_key}",
            event_type='plan_saved_s3',
            project_id=project_id,
            plan_id=plan_id,
            s3_key=s3_key
        )
    except Exception as e:
        logger.error(
            f"Error saving plan to S3",
            event_type='s3_error',
            error=e,
            project_id=project_id,
            plan_id=plan_id
        )


def send_tasks_to_dev_queue(project_id: str, plan_id: str, tasks: List[Dict[str, Any]]):
    """Send tasks to Dev agent queue for implementation."""
    try:
        for task in tasks:
            message = {
                'action': 'implement_task',
                'project_id': project_id,
                'plan_id': plan_id,
                'task': task,
                'timestamp': datetime.utcnow().isoformat()
            }
            
            sqs_client.send_message(
                QueueUrl=SQS_QUEUE_URL_DEV,
                MessageBody=json.dumps(message)
            )
        
        logger.info(f"Sent {len(tasks)} tasks to Dev queue")
    except Exception as e:
        logger.error(f"Error sending tasks to Dev queue: {e}")
        raise


def update_project_status(project_id: str, status: str):
    """Update project status in DynamoDB."""
    try:
        table.update_item(
            Key={
                'PK': f'PROJECT#{project_id}',
                'SK': 'METADATA'
            },
            UpdateExpression='SET #status = :status, updated_at = :updated_at',
            ExpressionAttributeNames={
                '#status': 'status'
            },
            ExpressionAttributeValues={
                ':status': status,
                ':updated_at': datetime.utcnow().isoformat()
            }
        )
        logger.info(f"Updated project {project_id} status to {status}")
    except Exception as e:
        logger.error(f"Error updating project status: {e}")


def process_planning_task(message_body: Dict[str, Any]) -> Dict[str, Any]:
    """
    Process a planning task from the queue.
    
    This function:
    1. Retrieves project context
    2. Generates a plan using LLM
    3. Saves the plan to DynamoDB and S3
    4. Sends tasks to Dev queue
    """
    try:
        action = message_body.get('action')
        project_id = message_body.get('project_id')
        
        if not project_id:
            raise ValueError('project_id is required')
        
        logger.info(f"Processing planning task for project {project_id}")
        
        # Get project from DynamoDB
        response = table.get_item(
            Key={
                'PK': f'PROJECT#{project_id}',
                'SK': 'METADATA'
            }
        )
        
        if 'Item' not in response:
            raise ValueError(f'Project {project_id} not found')
        
        project = response['Item']
        
        # Update project status
        update_project_status(project_id, 'planning')
        
        # Generate plan using LLM
        system_prompt = """You are a project management AI agent. 
        Generate a detailed implementation plan with specific tasks.
        Format your response as a structured list of tasks."""
        
        user_prompt = f"""
        Project: {project.get('name')}
        Type: {project.get('type')}
        Description: {project.get('description')}
        
        Generate a comprehensive implementation plan with specific tasks.
        """
        
        logger.info("Calling LLM for plan generation")
        llm_response = call_gemini_api(user_prompt, system_prompt)
        
        # Parse plan from response
        plan = parse_plan_from_response(llm_response)
        
        # Save plan to DynamoDB
        plan_id = save_plan_to_dynamodb(project_id, plan)
        
        # Save plan to S3
        save_plan_to_s3(project_id, plan_id, plan)
        
        # Send tasks to Dev queue
        if plan.get('tasks'):
            send_tasks_to_dev_queue(project_id, plan_id, plan['tasks'])
        
        # Update project status
        update_project_status(project_id, 'in_progress')
        
        return {
            'success': True,
            'project_id': project_id,
            'plan_id': plan_id,
            'tasks_count': len(plan.get('tasks', []))
        }
        
    except Exception as e:
        logger.error(f"Error processing planning task: {e}", exc_info=True)
        # Update project status to error
        if project_id:
            update_project_status(project_id, 'error')
        raise


def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """
    Lambda handler for PM Agent worker.
    
    Processes SQS messages containing planning tasks.
    """
    # Log Lambda invocation with context
    log_lambda_event(event, context, logger)
    
    # Set request ID for tracking
    logger.set_request_id(context.aws_request_id)
    
    logger.info(
        f"PM Agent worker invoked",
        event_type='worker_invoked',
        messages_count=len(event.get('Records', []))
    )
    
    results = []
    errors = []
    
    for record in event.get('Records', []):
        try:
            # Parse message body
            message_body = json.loads(record['body'])
            
            # Process the task
            result = process_planning_task(message_body)
            results.append(result)
            
            logger.info(
                f"Successfully processed message",
                event_type='message_processed',
                message_id=record['messageId'],
                project_id=result.get('project_id')
            )
            
        except Exception as e:
            logger.error(
                f"Error processing message",
                event_type='message_error',
                error=e,
                message_id=record.get('messageId')
            )
            errors.append({
                'messageId': record.get('messageId'),
                'error': str(e)
            })
    
    # Return summary
    response = {
        'processed': len(results),
        'errors': len(errors),
        'results': results
    }
    
    if errors:
        response['error_details'] = errors
    
    logger.info(
        f"PM Agent worker completed",
        event_type='worker_completed',
        processed=len(results),
        errors=len(errors)
    )
    
    # Log Lambda response
    log_lambda_response(response, context, logger)
    
    # If there were errors, raise exception to trigger retry/DLQ
    if errors:
        raise Exception(f"Failed to process {len(errors)} messages")
    
    return response
